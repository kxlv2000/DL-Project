{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6"
      ],
      "metadata": {
        "id": "itSgQQR85ScD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2589f4-2f53-462b-92d0-a79c824e40fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6) (1.22.4)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6) (2.0.0+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6) (2.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6) (1.11.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "Successfully installed sentencepiece-0.1.98 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "import string\n",
        "import time\n",
        "import random\n",
        "import numpy as np \n"
      ],
      "metadata": {
        "id": "q6i0gIDyLrSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random deletion\n",
        "\n",
        "def random_deletion(sentence, p):\n",
        "    # randomly delete some words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p, sentence))\n",
        "    # if all words are deleted, return the same sentence\n",
        "    if len(remaining) == 0:\n",
        "        return sentence\n",
        "    else:\n",
        "        return remaining\n",
        "        \n",
        "\n",
        "def IMDB_r_delete(train, test):\n",
        "  # apply random deletion to the input text of each example in the train set\n",
        "    for example in train.examples:\n",
        "      example.text = random_deletion(example.text, p=0.3) \n",
        "\n",
        "  # apply random deletion to the input text of each example in the test set\n",
        "    for example in test.examples:\n",
        "      example.text = random_deletion(example.text, p=0.3) \n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "g9debJRG1YMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "\n",
        "def tokenize(input):\n",
        "    \"\"\"\n",
        "        Naive tokenizer, that lower-cases the input\n",
        "        and splits on punctuation and whitespace\n",
        "    \"\"\"\n",
        "    input = input.lower()\n",
        "    for p in string.punctuation:\n",
        "        input = input.replace(p,\" \")\n",
        "    return input.strip().split()\n",
        "\n",
        "\n",
        "def num2words(vocab,vec):\n",
        "    \"\"\"\n",
        "        Converts a vector of word indicies\n",
        "        to a list of strings\n",
        "    \"\"\"\n",
        "    return [vocab.itos[i] for i in vec]\n",
        "\n",
        "def get_imdb(batch_size,max_length):\n",
        "\n",
        "    # Defines a datatype together with instructions for converting to Tensor.\n",
        "    # lower: Whether to lowercase the text in this field. Default: False.\n",
        "    # include_lengths: Whether to return a tuple of a padded minibatch and a list containing the lengths of each\n",
        "    # examples, or just a padded minibatch. Default: False.\n",
        "    # batch_first: Whether to produce tensors with the batch dimension first. Default: False.\n",
        "    # tokenize: The function used to tokenize strings using this field into sequential examples. If \"spacy\", the SpaCy\n",
        "    # English tokenizer is used. Default: str.split.\n",
        "    TEXT = data.Field(lower=True, include_lengths=True, batch_first=True, tokenize=tokenize, fix_length=max_length)\n",
        "    # sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.\n",
        "    # unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n",
        "    # pad_token: The string token used as padding. Default: \"<pad>\".\n",
        "    LABEL = data.Field(sequential=False, unk_token=None, pad_token=None)\n",
        "\n",
        "    print(\"Loading data..\\n\")\n",
        "\n",
        "    # make splits for data\n",
        "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "    # print information about the data\n",
        "    print('train.fields', train.fields)\n",
        "    print('len(train)', len(train))\n",
        "    print('len(test)', len(test))\n",
        "    print(\"\")\n",
        "\n",
        "    # random deletion —— enable this for random deletion data augmentation\n",
        "    #train, test = IMDB_r_delete(train, test)\n",
        "\n",
        "    # build the vocabulary\n",
        "    TEXT.build_vocab(train, vectors=GloVe(name='42B', dim=300,max_vectors=500000))\n",
        "    LABEL.build_vocab(train)\n",
        "\n",
        "    # print vocab information\n",
        "    print('len(TEXT.vocab)', len(TEXT.vocab))\n",
        "    print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\n",
        "\n",
        "    # make iterator for splits\n",
        "    train_iter, test_iter = data.BucketIterator.splits(\n",
        "        (train, test), batch_size=batch_size)\n",
        "\n",
        "    return train_iter, test_iter, TEXT.vocab.vectors, TEXT.vocab\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "        If run seperately, does a simple sanity check,\n",
        "        by printing different values,\n",
        "        and counting labels\n",
        "    \"\"\"\n",
        "    train, test, vectors, vocab = get_imdb(1,50)\n",
        "\n",
        "    from collections import Counter\n",
        "    print(list(enumerate(vocab.itos[:100])))\n",
        "    cnt = Counter()\n",
        "    for i,b in enumerate(iter(train)):\n",
        "        if i > 2: \n",
        "          break\n",
        "        print(i,num2words(vocab,b.text[0][0].numpy()))\n",
        "        cnt[b.label[0].item()] += 1\n",
        "    print(cnt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A29gds2KXgK-",
        "outputId": "57b6a9a8-56ac-465a-e0ae-e8a9997d0786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data..\n",
            "\n",
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 24.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.fields {'text': <torchtext.data.field.Field object at 0x7f33ccca1790>, 'label': <torchtext.data.field.Field object at 0x7f33ccca1e20>}\n",
            "len(train) 25000\n",
            "len(test) 25000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.42B.300d.zip: 1.88GB [05:53, 5.31MB/s]                            \n",
            "100%|█████████▉| 499999/500000 [00:56<00:00, 8786.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(TEXT.vocab) 75396\n",
            "TEXT.vocab.vectors.size() torch.Size([75396, 300])\n",
            "[(0, '<unk>'), (1, '<pad>'), (2, 'the'), (3, 'and'), (4, 'a'), (5, 'of'), (6, 'to'), (7, 'is'), (8, 'br'), (9, 'it'), (10, 'in'), (11, 'i'), (12, 'this'), (13, 'that'), (14, 's'), (15, 'was'), (16, 'as'), (17, 'for'), (18, 'with'), (19, 'movie'), (20, 'but'), (21, 'film'), (22, 't'), (23, 'you'), (24, 'on'), (25, 'not'), (26, 'he'), (27, 'are'), (28, 'his'), (29, 'have'), (30, 'be'), (31, 'one'), (32, 'all'), (33, 'at'), (34, 'they'), (35, 'by'), (36, 'an'), (37, 'who'), (38, 'so'), (39, 'from'), (40, 'like'), (41, 'there'), (42, 'her'), (43, 'or'), (44, 'just'), (45, 'about'), (46, 'out'), (47, 'if'), (48, 'has'), (49, 'what'), (50, 'some'), (51, 'good'), (52, 'can'), (53, 'more'), (54, 'she'), (55, 'when'), (56, 'very'), (57, 'up'), (58, 'time'), (59, 'no'), (60, 'even'), (61, 'my'), (62, 'would'), (63, 'which'), (64, 'story'), (65, 'only'), (66, 'really'), (67, 'see'), (68, 'their'), (69, 'had'), (70, 'we'), (71, 'were'), (72, 'me'), (73, 'well'), (74, 'than'), (75, 'much'), (76, 'get'), (77, 'bad'), (78, 'been'), (79, 'people'), (80, 'will'), (81, 'do'), (82, 'other'), (83, 'also'), (84, 'into'), (85, 'first'), (86, 'great'), (87, 'because'), (88, 'how'), (89, 'him'), (90, 'don'), (91, 'most'), (92, 'made'), (93, 'its'), (94, 'then'), (95, 'make'), (96, 'way'), (97, 'them'), (98, 'could'), (99, 'too')]\n",
            "0 ['hmmm', 'where', 'to', 'start', 'how', 'does', 'a', 'serious', 'actress', 'like', 'demi', 'moore', 'got', 'involved', 'in', 'such', 'crap', 'first', 'blood', 'might', 'be', 'rated', 'as', 'bull', 't', 'but', 'this', 'type', 'of', 'nonsense', 'is', 'just', 'rambo', 'with', 'tits', 'point', 'of', 'course', 'if', 'you', 'are', 'interested', 'in', 'the', 'crapstory', 'demi', 'moore', 'just', 'wants', 'to']\n",
            "1 ['after', 'seeing', 'only', 'half', 'of', 'the', 'film', 'in', 'school', 'back', 'in', 'november', 'today', 'i', 'saw', 'that', 'it', 'was', 'on', 'flix', 'channel', 'and', 'decided', 'to', 'watch', 'it', 'to', 'see', 'the', 'rest', 'of', 'it', 'and', 'to', 'write', 'a', 'new', 'review', 'on', 'it', 'br', 'br', 'the', 'book', 'that', 'the', 'film', 'is', 'based', 'on']\n",
            "2 ['buffs', 'of', 'the', 'adult', 'western', 'that', 'flourished', 'in', 'the', '1950s', 'try', 'and', 'trace', 'its', 'origins', 'to', 'the', 'film', 'that', 'kicked', 'off', 'the', 'syndrome', 'of', 'course', 'we', 'can', 'go', 'back', 'to', 'howard', 'hawks', 's', 'red', 'river', '1948', 'or', 'further', 'still', 'to', 'john', 'ford', 's', 'my', 'darling', 'clementine', '1946', 'but', 'if', 'we']\n",
            "Counter({0: 2, 1: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos\n",
        "\n",
        "def get_pos_onehot(length):\n",
        "    # initial zero matrix [length, length]\n",
        "    onehot = torch.zeros(length, length)\n",
        "    # torch.arrange(length).long() 生成[0-length]的tensor，.view(-1, 1)转变为length行，1列\n",
        "    idxs = torch.arange(length).long().view(-1, 1)\n",
        "    # onehot.scatter_(1, idxs, 1)生成[idxs, idxs]的对角单位阵\n",
        "    onehot.scatter_(1, idxs, 1)\n",
        "    return onehot\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(get_pos_onehot(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9fd-_CsTpPW",
        "outputId": "792eef27-d514-47fa-8245-3efb2c9fa7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "\n",
        "#from pos import get_pos_onehot\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "        A multihead attention module,\n",
        "        using scaled dot-product attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.head_size = int(self.hidden_size / num_heads)\n",
        "        # weighted sum\n",
        "        self.q_linear = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.k_linear = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.v_linear = nn.Linear(self.input_size, self.hidden_size)\n",
        "        #\n",
        "        self.joint_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        # project the queries, keys and values by their respective weight matrices\n",
        "        q_proj = self.q_linear(q).view(q.size(0), q.size(1), self.num_heads, self.head_size).transpose(1, 2)\n",
        "        k_proj = self.k_linear(k).view(k.size(0), k.size(1), self.num_heads, self.head_size).transpose(1, 2)\n",
        "        v_proj = self.v_linear(v).view(v.size(0), v.size(1), self.num_heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "        # calculate attention weights\n",
        "        unscaled_weights = torch.matmul(q_proj, k_proj.transpose(2, 3))  # transpose the 2nd and 3rd dim\n",
        "        weights = self.softmax(unscaled_weights / torch.sqrt(torch.Tensor([self.head_size * 1.0]).to(unscaled_weights)))\n",
        "\n",
        "        # weight values by their corresponding attention weights\n",
        "        weighted_v = torch.matmul(weights, v_proj)\n",
        "        \n",
        "        weighted_v = weighted_v.transpose(1, 2).contiguous()\n",
        "\n",
        "        # do a linear projection of the weighted sums of values\n",
        "        joint_proj = self.joint_linear(weighted_v.view(q.size(0), q.size(1), self.hidden_size))\n",
        "\n",
        "        # store a reference to attention weights, for THIS forward pass,\n",
        "        # for visualisation purposes\n",
        "        self.weights = weights\n",
        "\n",
        "        return joint_proj\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"\n",
        "        One block of the transformer.\n",
        "        Contains a multihead attention sublayer\n",
        "        followed by a feed forward network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_heads, activation=nn.ReLU, dropout=None):\n",
        "        super(Block, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attention = MultiHeadAttention(input_size, hidden_size, num_heads)\n",
        "        self.attention_norm = nn.LayerNorm(input_size)\n",
        "\n",
        "        ff_layers = [\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            activation(),\n",
        "            nn.Linear(hidden_size, input_size),\n",
        "        ]\n",
        "\n",
        "        if self.dropout:\n",
        "            self.attention_dropout = nn.Dropout(dropout)\n",
        "            ff_layers.append(nn.Dropout(dropout))\n",
        "        # nn.Sequential(): Modules will be added to it in the order they are passed in the constructor. Alternatively,\n",
        "        # an ordered dict of modules can also be passed in.\n",
        "        self.ff = nn.Sequential(*ff_layers)\n",
        "        self.ff_norm = nn.LayerNorm(input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attended = self.attention_norm(self.attention_dropout(self.attention(x, x, x)) + x)\n",
        "        return self.ff_norm(self.ff(attended) + x)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, ff_size, num_blocks, num_heads, activation=nn.ReLU, dropout=None):\n",
        "        \"\"\"\n",
        "            A single Transformer Network\n",
        "            input_size: hidden weight\n",
        "            hidden_size: hidden weight\n",
        "            ff_size: hiden weight\n",
        "        \"\"\"\n",
        "        super(Transformer, self).__init__()\n",
        "        # construct num_blocks block, no residual structure\n",
        "        self.blocks = nn.Sequential(*[Block(input_size, hidden_size, num_heads, activation, dropout=dropout)\n",
        "                                      for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            Sequentially applies the blocks of the Transformer network\n",
        "        \"\"\"\n",
        "        return self.blocks(x)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "        A neural network that encodes a sequence\n",
        "        using a Transformer network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embeddings, max_length, model_size=128, num_heads=4, num_blocks=1, dropout=0.1,\n",
        "                 train_word_embeddings=True):\n",
        "        super(Net, self).__init__()\n",
        "        # Creates Embedding instance from given 2-dimensional FloatTensor.\n",
        "        # embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
        "        # First dimension is being passed to Embedding as 'num_embeddings', second as 'embedding_dim'.\n",
        "        # freeze (boolean, optional): If ``True``, the tensor does not get updated in the learning process.\n",
        "        # Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
        "        self.embeddings = nn.Embedding.from_pretrained(embeddings, freeze=not train_word_embeddings)\n",
        "        self.model_size = model_size\n",
        "        # Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
        "        # outputsize=[embedding.size(1), self.model_size]\n",
        "        # embedding weighted sum\n",
        "        self.emb_ff = nn.Linear(embeddings.size(1), self.model_size)\n",
        "        self.pos = nn.Linear(max_length, self.model_size)\n",
        "        self.max_length = max_length\n",
        "        self.transformer = Transformer(self.model_size, self.model_size, self.model_size, num_blocks, num_heads,\n",
        "                                       dropout=dropout)\n",
        "        # 2: biclass\n",
        "        self.output = nn.Linear(self.model_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        x = x.view(-1)  # x.view(-1) transpose x to one row\n",
        "        x = self.emb_ff(self.embeddings(x))\n",
        "        pos = self.pos(get_pos_onehot(self.max_length).to(x)).unsqueeze(0)\n",
        "        x = x.view(*(x_size + (self.model_size,)))\n",
        "        x += pos\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.output(x)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "        If run seperately, does a simple sanity check,\n",
        "        by doing a random forward pass\n",
        "    \"\"\"\n",
        "    t = Transformer(10, 20, 30, 3, 5)\n",
        "    print(t)\n",
        "    input = Variable(torch.rand(40, 20, 10))\n",
        "    print(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxTvpvWLUL6C",
        "outputId": "f1e862b8-3eb1-4088-9806-f87ecafaa38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (attention): MultiHeadAttention(\n",
            "        (q_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (k_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (v_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (joint_linear): Linear(in_features=20, out_features=20, bias=True)\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "      (attention_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): Sequential(\n",
            "        (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "      )\n",
            "      (ff_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): Block(\n",
            "      (attention): MultiHeadAttention(\n",
            "        (q_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (k_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (v_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (joint_linear): Linear(in_features=20, out_features=20, bias=True)\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "      (attention_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): Sequential(\n",
            "        (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "      )\n",
            "      (ff_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): Block(\n",
            "      (attention): MultiHeadAttention(\n",
            "        (q_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (k_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (v_linear): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (joint_linear): Linear(in_features=20, out_features=20, bias=True)\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "      (attention_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): Sequential(\n",
            "        (0): Linear(in_features=10, out_features=20, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=20, out_features=10, bias=True)\n",
            "      )\n",
            "      (ff_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "tensor([[[0.7396, 0.1369, 0.9677,  ..., 0.7193, 0.5946, 0.5244],\n",
            "         [0.6821, 0.9250, 0.3773,  ..., 0.3285, 0.8771, 0.7913],\n",
            "         [0.1227, 0.9268, 0.7404,  ..., 0.6282, 0.0633, 0.3971],\n",
            "         ...,\n",
            "         [0.8365, 0.2905, 0.8984,  ..., 0.3942, 0.0602, 0.0157],\n",
            "         [0.5622, 0.0322, 0.6013,  ..., 0.2412, 0.1770, 0.8882],\n",
            "         [0.2074, 0.8077, 0.1582,  ..., 0.6387, 0.9303, 0.5112]],\n",
            "\n",
            "        [[0.7084, 0.1960, 0.4751,  ..., 0.8380, 0.7824, 0.7589],\n",
            "         [0.3197, 0.9029, 0.0367,  ..., 0.9643, 0.4659, 0.5136],\n",
            "         [0.5636, 0.6719, 0.0944,  ..., 0.1769, 0.9348, 0.2431],\n",
            "         ...,\n",
            "         [0.5282, 0.1938, 0.6032,  ..., 0.9512, 0.7530, 0.0068],\n",
            "         [0.9454, 0.1978, 0.8341,  ..., 0.2170, 0.3841, 0.6781],\n",
            "         [0.3929, 0.7099, 0.6632,  ..., 0.7201, 0.6212, 0.5684]],\n",
            "\n",
            "        [[0.4219, 0.6519, 0.7262,  ..., 0.9326, 0.3653, 0.8979],\n",
            "         [0.7619, 0.3330, 0.9067,  ..., 0.4842, 0.6567, 0.9409],\n",
            "         [0.8858, 0.9085, 0.2713,  ..., 0.6731, 0.2365, 0.7105],\n",
            "         ...,\n",
            "         [0.5444, 0.9260, 0.0668,  ..., 0.7791, 0.0897, 0.1478],\n",
            "         [0.5190, 0.3945, 0.5778,  ..., 0.6710, 0.7684, 0.0974],\n",
            "         [0.7222, 0.3565, 0.5508,  ..., 0.7782, 0.4879, 0.2850]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.7437, 0.3931, 0.8442,  ..., 0.2919, 0.1563, 0.5796],\n",
            "         [0.7186, 0.1073, 0.5297,  ..., 0.7181, 0.8178, 0.1172],\n",
            "         [0.0550, 0.2163, 0.6278,  ..., 0.6731, 0.8223, 0.8224],\n",
            "         ...,\n",
            "         [0.4811, 0.5882, 0.2812,  ..., 0.8629, 0.9887, 0.8635],\n",
            "         [0.1772, 0.4281, 0.5325,  ..., 0.9667, 0.0666, 0.9910],\n",
            "         [0.3034, 0.8612, 0.6636,  ..., 0.6184, 0.6527, 0.3407]],\n",
            "\n",
            "        [[0.7852, 0.6764, 0.5743,  ..., 0.5763, 0.7322, 0.3084],\n",
            "         [0.6229, 0.2779, 0.7148,  ..., 0.9032, 0.1534, 0.1238],\n",
            "         [0.0877, 0.7231, 0.2436,  ..., 0.2271, 0.0145, 0.8455],\n",
            "         ...,\n",
            "         [0.0770, 0.5754, 0.2814,  ..., 0.5052, 0.5054, 0.2392],\n",
            "         [0.1180, 0.7118, 0.7969,  ..., 0.8813, 0.4052, 0.4857],\n",
            "         [0.8612, 0.0573, 0.2133,  ..., 0.6967, 0.7198, 0.3579]],\n",
            "\n",
            "        [[0.3337, 0.7844, 0.1103,  ..., 0.3986, 0.7820, 0.2577],\n",
            "         [0.3442, 0.4142, 0.5632,  ..., 0.1132, 0.6949, 0.8854],\n",
            "         [0.9891, 0.4658, 0.2442,  ..., 0.6510, 0.5550, 0.3115],\n",
            "         ...,\n",
            "         [0.8313, 0.7494, 0.0978,  ..., 0.3282, 0.0530, 0.2080],\n",
            "         [0.0063, 0.8670, 0.7465,  ..., 0.4856, 0.9820, 0.8834],\n",
            "         [0.8272, 0.4251, 0.5383,  ..., 0.3592, 0.4949, 0.9780]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper\n",
        "\n",
        "def plot_weights(model, windows, b, vocab, vis):\n",
        "    # b: words\n",
        "    try:\n",
        "        weights = model.transformer.blocks[0].attention.weights.to(\"cpu\").numpy()\n",
        "    except AttributeError:\n",
        "        print(\"No weights yet\")\n",
        "        return None\n",
        "    idx = 1\n",
        "    text, dims = b.text[0], b.text[1]\n",
        "    if windows is None:\n",
        "        windows = [None] * weights.shape[0]\n",
        "    new_windows = []\n",
        "    weights = weights[idx]\n",
        "    dims = dims[idx].item()\n",
        "    names = num2words(vocab, text[idx].numpy()[:dims])\n",
        "    weights = weights[:, :dims, :dims]\n",
        "\n",
        "    for weight, window in zip(weights, windows):\n",
        "        new_windows.append(vis.heatmap(weight, opts=dict(columnnames=names, rownames=names), win=window))\n",
        "    return new_windows"
      ],
      "metadata": {
        "id": "oaYqmMKAUd_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "try:\n",
        "    # try to import tqdm for progress updates\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    # on failure, make tqdm a noop\n",
        "    def tqdm(x):\n",
        "        return x\n",
        "\n",
        "try:\n",
        "    # try to import visdom for visualisation of attention weights\n",
        "    import visdom\n",
        "    #from helpers import plot_weights\n",
        "\n",
        "    vis = visdom.Visdom()\n",
        "except ImportError:\n",
        "    vis = None\n",
        "    pass\n",
        "\n",
        "\n",
        "def val(model, test, vocab, device, epoch_num, path_saving): #加了一个f\n",
        "    \"\"\"\n",
        "        Evaluates model on the test set\n",
        "    \"\"\"\n",
        "    # model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will\n",
        "    # work in eval model instead of training mode.\n",
        "\n",
        "    model.eval()\n",
        "    print(\"\\nValidating..\")\n",
        "    if not vis is None:\n",
        "        visdom_windows = None\n",
        "    # impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you\n",
        "    # won’t be able to backprop (which you don’t want in an eval script).\n",
        "    with torch.no_grad():\n",
        "        acc = 0.0\n",
        "        total = 0.0\n",
        "        for i, b in enumerate(tqdm(test)):\n",
        "            if not vis is None and i == 0:\n",
        "                visdom_windows = plot_weights(model, visdom_windows, b, vocab, vis)\n",
        "            model_out = model(b.text[0].to(device)).to(\"cpu\").numpy()\n",
        "            acc += (model_out.argmax(axis=1) == b.label.numpy()).sum()\n",
        "            total += b.label.size(0)\n",
        "        with open(path_saving + '_val_results', 'a', encoding='utf-8') as file:\n",
        "            temp = \"epoach:{}, accuracy:{}%, acc, samples/total samples{}/{}\".format(epoch_num, acc / total,\n",
        "                                                  acc, total)\n",
        "            file.write(temp + '\\n')\n",
        "        print(temp)\n",
        "    return acc / total\n",
        "\n",
        "\n",
        "def train(max_length, model_size, epochs, learning_rate, device, num_heads, num_blocks, dropout, train_word_embeddings,\n",
        "          batch_size, save_path,f): \n",
        "    \"\"\"\n",
        "        Trains the classifier on the IMDB sentiment dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # random seed\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # train start\n",
        "\n",
        "    train, test, vectors, vocab = get_imdb(batch_size, max_length=max_length)\n",
        "    # creat the transformer net\n",
        "    model = Net(model_size=model_size, embeddings=vectors, max_length=max_length, num_heads=num_heads,\n",
        "                num_blocks=num_blocks, dropout=dropout, train_word_embeddings=train_word_embeddings).to(device)\n",
        "\n",
        "    optimizer = optim.Adam((p for p in model.parameters() if p.requires_grad), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_correct = 0\n",
        "    with open(save_path + '_train_results', 'a', encoding='utf-8') as file_re:\n",
        "        for i in range(0, epochs + 1):\n",
        "            loss_sum = 0.0\n",
        "            total_correct = 0\n",
        "            total = 0\n",
        "\n",
        "            model.train()\n",
        "\n",
        "            # train data has been spited many batch, tadm: print progress bar\n",
        "            for j, b in enumerate(iter(tqdm(train))):\n",
        "                optimizer.zero_grad()\n",
        "                model_out = model(b.text[0].to(device))\n",
        "                predictions = torch.argmax(model_out, dim=1)\n",
        "                total_correct += torch.sum(predictions == b.label.to(device)).item()\n",
        "                total += len(b.label)\n",
        "\n",
        "                # calculate loss\n",
        "                loss = criterion(model_out, b.label.to(device))\n",
        "                \n",
        "                # L2 regularization: introduce penalty term to loss function\n",
        "                l2_loss = torch.tensor(0., requires_grad=True)\n",
        "                for name, param in model.named_parameters():\n",
        "                  if 'weight' in name:\n",
        "                    l2_loss = l2_loss + torch.norm(param, p=2)\n",
        "                loss = loss + 0.001 * l2_loss\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                loss_sum += loss.item()\n",
        "            train_acc = total_correct / total\n",
        "            print('\\n **********************************************')\n",
        "            loss_temp = \"Epoch: {}, Loss mean: {}\".format(i, loss_sum / j)\n",
        "            acc_temp = \"Training accuracy: {:.2f}%\".format(train_acc * 100)\n",
        "            file_re.write(loss_temp + acc_temp +'\\n')\n",
        "            print(loss_temp,acc_temp)\n",
        "            # Validate on test-set every epoch\n",
        "            if i % 5 == 0:\n",
        "                val_correct = val(model, test, vocab, device, i, save_path)\n",
        "            if val_correct > best_correct:\n",
        "                best_correct = val_correct\n",
        "                best_model = model\n",
        "    torch.save(best_model, save_path + '_model.pkl')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    ap = argparse.ArgumentParser(description=\"Train a Transformer network for sentiment analysis\")\n",
        "    ap.add_argument(\"--max_length\", default=500, type=int, help=\"Maximum sequence length, sequences longer than this \\\n",
        "                                                                are truncated\")\n",
        "    ap.add_argument(\"--model_size\", default=128, type=int, help=\"Hidden size for all hidden layers of the model\")\n",
        "    ap.add_argument(\"--epochs\", default=50, type=int, help=\"Number of epochs to train for\")\n",
        "    ap.add_argument(\"--learning_rate\", default=1e-5, type=float, dest=\"learning_rate\",\n",
        "                    help=\"Learning rate for optimizer\")\n",
        "    ap.add_argument(\"--device\", default=\"cuda:0\", dest=\"device\", help=\"Device to use for training and evaluation \\\n",
        "                                                                      e.g. (cpu, cuda:0)\")\n",
        "    ap.add_argument(\"--num_heads\", default=4, type=int, dest=\"num_heads\", help=\"Number of attention heads in the \\\n",
        "                                                                               Transformer network\")\n",
        "    ap.add_argument(\"--num_blocks\", default=1, type=int, dest=\"num_blocks\",\n",
        "                    help=\"Number of blocks in the Transformer network\")\n",
        "    ap.add_argument(\"--dropout\", default=0.2, type=float, dest=\"dropout\", help=\"Dropout (not keep_prob, but probability \\\n",
        "                                                            of ZEROING during training, i.e. keep_prob = 1 - dropout)\")\n",
        "    ap.add_argument(\"--train_word_embeddings\", type=bool, default=True, dest=\"train_word_embeddings\",\n",
        "                    help=\"Train GloVE word embeddings\")\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size\")\n",
        "    ap.add_argument(\"--save_path\", default=r'./res' +time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time())),\n",
        "                    dest=\"save_path\",\n",
        "                    help=\"The path to save the results\")\n",
        "    ap.add_argument('-f')\n",
        "\n",
        "\n",
        "    args = vars(ap.parse_args())\n",
        "    train(**args)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FZibFdLTUd4E",
        "outputId": "c5f46f89-c26d-417b-bd40-588056316efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data..\n",
            "\n",
            "train.fields {'text': <torchtext.data.field.Field object at 0x7f4bf1322280>, 'label': <torchtext.data.field.Field object at 0x7f4bf1322b80>}\n",
            "len(train) 25000\n",
            "len(test) 25000\n",
            "\n",
            "len(TEXT.vocab) 65866\n",
            "TEXT.vocab.vectors.size() torch.Size([65866, 300])\n",
            "Training accuracy: 50.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 0, Loss mean: 2.2672234101173205\n",
            " Training accuracy: 52.64%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 46.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:0, accuracy:0.564%, acc, samples/total samples14100.0/25000.0\n",
            "Training accuracy: 62.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 1, Loss mean: 2.2385172672760794\n",
            " Training accuracy: 63.31%\n",
            "Training accuracy: 67.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 2, Loss mean: 2.1882044987800793\n",
            " Training accuracy: 68.15%\n",
            "Training accuracy: 70.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 3, Loss mean: 2.1072448109969115\n",
            " Training accuracy: 72.15%\n",
            "Training accuracy: 75.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 4, Loss mean: 2.0287403497940453\n",
            " Training accuracy: 76.81%\n",
            "Training accuracy: 79.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 5, Loss mean: 1.9739458163579304\n",
            " Training accuracy: 80.26%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:5, accuracy:0.8082%, acc, samples/total samples20205.0/25000.0\n",
            "Training accuracy: 81.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 6, Loss mean: 1.9417300462722777\n",
            " Training accuracy: 81.85%\n",
            "Training accuracy: 82.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 7, Loss mean: 1.9216576441740378\n",
            " Training accuracy: 82.74%\n",
            "Training accuracy: 83.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 8, Loss mean: 1.9047488188132262\n",
            " Training accuracy: 83.47%\n",
            "Training accuracy: 83.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 9, Loss mean: 1.8909774071130998\n",
            " Training accuracy: 84.04%\n",
            "Training accuracy: 84.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 10, Loss mean: 1.8787811123407805\n",
            " Training accuracy: 84.77%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:10, accuracy:0.83528%, acc, samples/total samples20882.0/25000.0\n",
            "Training accuracy: 85.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 11, Loss mean: 1.8676033924787472\n",
            " Training accuracy: 85.13%\n",
            "Training accuracy: 84.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 12, Loss mean: 1.8573236416547727\n",
            " Training accuracy: 85.13%\n",
            "Training accuracy: 85.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 13, Loss mean: 1.8486800074577332\n",
            " Training accuracy: 85.81%\n",
            "Training accuracy: 85.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 14, Loss mean: 1.8393888433774312\n",
            " Training accuracy: 85.94%\n",
            "Training accuracy: 85.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 15, Loss mean: 1.8309649458298316\n",
            " Training accuracy: 86.06%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 44.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:15, accuracy:0.84112%, acc, samples/total samples21028.0/25000.0\n",
            "Training accuracy: 86.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 16, Loss mean: 1.822706543176602\n",
            " Training accuracy: 86.42%\n",
            "Training accuracy: 86.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 17, Loss mean: 1.8147150975007278\n",
            " Training accuracy: 86.54%\n",
            "Training accuracy: 86.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 18, Loss mean: 1.807187393384102\n",
            " Training accuracy: 86.90%\n",
            "Training accuracy: 87.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 19, Loss mean: 1.7991952229768802\n",
            " Training accuracy: 87.30%\n",
            "Training accuracy: 87.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 20, Loss mean: 1.791552196099208\n",
            " Training accuracy: 87.48%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:20, accuracy:0.85056%, acc, samples/total samples21264.0/25000.0\n",
            "Training accuracy: 87.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 21, Loss mean: 1.784123156620906\n",
            " Training accuracy: 87.60%\n",
            "Training accuracy: 87.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 22, Loss mean: 1.7782765837816092\n",
            " Training accuracy: 87.71%\n",
            "Training accuracy: 88.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 23, Loss mean: 1.7699293750983018\n",
            " Training accuracy: 87.98%\n",
            "Training accuracy: 88.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 24, Loss mean: 1.7627868640117157\n",
            " Training accuracy: 88.15%\n",
            "Training accuracy: 88.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 25, Loss mean: 1.7557723852304312\n",
            " Training accuracy: 88.33%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:25, accuracy:0.85752%, acc, samples/total samples21438.0/25000.0\n",
            "Training accuracy: 88.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 26, Loss mean: 1.7490064847163664\n",
            " Training accuracy: 88.60%\n",
            "Training accuracy: 88.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 27, Loss mean: 1.7428448606760074\n",
            " Training accuracy: 88.68%\n",
            "Training accuracy: 88.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 28, Loss mean: 1.7357862753745836\n",
            " Training accuracy: 88.84%\n",
            "Training accuracy: 88.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 29, Loss mean: 1.7291728255076286\n",
            " Training accuracy: 88.90%\n",
            "Training accuracy: 89.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 30, Loss mean: 1.7221825034190448\n",
            " Training accuracy: 89.15%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:30, accuracy:0.86132%, acc, samples/total samples21533.0/25000.0\n",
            "Training accuracy: 89.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 31, Loss mean: 1.7160539275560625\n",
            " Training accuracy: 89.41%\n",
            "Training accuracy: 89.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 32, Loss mean: 1.7095669969534262\n",
            " Training accuracy: 89.46%\n",
            "Training accuracy: 89.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 33, Loss mean: 1.7019805370232999\n",
            " Training accuracy: 89.72%\n",
            "Training accuracy: 89.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 34, Loss mean: 1.6961183801675455\n",
            " Training accuracy: 89.92%\n",
            "Training accuracy: 89.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 35, Loss mean: 1.6891993886385208\n",
            " Training accuracy: 89.92%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:35, accuracy:0.86388%, acc, samples/total samples21597.0/25000.0\n",
            "Training accuracy: 90.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 36, Loss mean: 1.6824404435280043\n",
            " Training accuracy: 90.26%\n",
            "Training accuracy: 90.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 37, Loss mean: 1.677419591255677\n",
            " Training accuracy: 90.28%\n",
            "Training accuracy: 90.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 38, Loss mean: 1.669627178632296\n",
            " Training accuracy: 90.61%\n",
            "Training accuracy: 90.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 39, Loss mean: 1.6633041314589672\n",
            " Training accuracy: 90.42%\n",
            "Training accuracy: 91.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 40, Loss mean: 1.6576639954860395\n",
            " Training accuracy: 90.99%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 44.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:40, accuracy:0.8606%, acc, samples/total samples21515.0/25000.0\n",
            "Training accuracy: 91.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 41, Loss mean: 1.6528620469264494\n",
            " Training accuracy: 91.00%\n",
            "Training accuracy: 91.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 42, Loss mean: 1.64460511360413\n",
            " Training accuracy: 91.18%\n",
            "Training accuracy: 91.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 43, Loss mean: 1.639646767347287\n",
            " Training accuracy: 91.18%\n",
            "Training accuracy: 91.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 44, Loss mean: 1.6330218110329067\n",
            " Training accuracy: 91.44%\n",
            "Training accuracy: 91.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 45, Loss mean: 1.6255693765786978\n",
            " Training accuracy: 91.70%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 46.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:45, accuracy:0.86664%, acc, samples/total samples21666.0/25000.0\n",
            "Training accuracy: 91.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 46, Loss mean: 1.6200534496551906\n",
            " Training accuracy: 91.83%\n",
            "Training accuracy: 92.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 47, Loss mean: 1.6138804793357848\n",
            " Training accuracy: 92.13%\n",
            "Training accuracy: 92.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 48, Loss mean: 1.607458866865207\n",
            " Training accuracy: 92.30%\n",
            "Training accuracy: 92.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:24<00:00, 16.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 49, Loss mean: 1.600793977578481\n",
            " Training accuracy: 92.22%\n",
            "Training accuracy: 92.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:23<00:00, 16.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " **********************************************\n",
            "Epoch: 50, Loss mean: 1.594854728380839\n",
            " Training accuracy: 92.53%\n",
            "\n",
            "Validating..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoach:50, accuracy:0.8648%, acc, samples/total samples21620.0/25000.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-167aa9779680>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-167aa9779680>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(max_length, model_size, epochs, learning_rate, device, num_heads, num_blocks, dropout, train_word_embeddings, batch_size, save_path, fig_name, f)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-68122e1fecbb>\u001b[0m in \u001b[0;36mplot_acc\u001b[0;34m(train_acc, val_acc, fig_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#plt.title(fig_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#np.savez(os.path.join('./', fig_name.replace('.png ', '.npz')), train_acc=train_acc, val_acc=val_acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: savefig() takes 2 positional arguments but 3 were given"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}