{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-22T06:02:36.190432Z","iopub.status.busy":"2023-04-22T06:02:36.189996Z","iopub.status.idle":"2023-04-22T06:02:44.860250Z","shell.execute_reply":"2023-04-22T06:02:44.859444Z","shell.execute_reply.started":"2023-04-22T06:02:36.190356Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 12.7MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (1.9.212)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (4.32.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (1.17.0)\n","Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (1.2.0)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (2019.8.19)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (0.1.83)\n","Collecting sacremoses (from pytorch-transformers)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/78/fef8d089db5b97546fd6d1ff2e813b8544e85670bf3a8c378c9d0250b98d/sacremoses-0.0.53.tar.gz (880kB)\n","\u001b[K     |████████████████████████████████| 880kB 37.5MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch-transformers) (2.22.0)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.212 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-transformers) (1.12.212)\n","Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->pytorch-transformers) (1.12.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->pytorch-transformers) (7.0)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->pytorch-transformers) (0.13.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-transformers) (2019.6.16)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-transformers) (1.24.2)\n","Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.212->boto3->pytorch-transformers) (2.8.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.212->boto3->pytorch-transformers) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-cp36-none-any.whl size=895252 sha256=da5466c22dd7598626e009cf9c84321c173d09fc66275418e72342474db713f4\n","  Stored in directory: /root/.cache/pip/wheels/56/d5/b2/bc878b2bbddfbcc8fd62ca73c4fd842bd28c1fd3dbdf424c74\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.53\n"]}],"source":["! pip install pytorch-transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.468423Z","start_time":"2019-09-02T13:42:46.505711Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:44.862968Z","iopub.status.busy":"2023-04-22T06:02:44.862522Z","iopub.status.idle":"2023-04-22T06:02:48.391435Z","shell.execute_reply":"2023-04-22T06:02:48.390613Z","shell.execute_reply.started":"2023-04-22T06:02:44.862917Z"},"trusted":true},"outputs":[],"source":["from fastai.text import *\n","from fastai.metrics import *\n","from pytorch_transformers import RobertaTokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.474401Z","start_time":"2019-09-02T13:42:47.470059Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:48.393191Z","iopub.status.busy":"2023-04-22T06:02:48.392873Z","iopub.status.idle":"2023-04-22T06:02:48.407155Z","shell.execute_reply":"2023-04-22T06:02:48.406218Z","shell.execute_reply.started":"2023-04-22T06:02:48.393144Z"},"trusted":true},"outputs":[],"source":["# Creating a config object to store task specific information\n","class Config(dict):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","    \n","    def set(self, key, val):\n","        self[key] = val\n","        setattr(self, key, val)\n","        \n","config = Config(\n","    testing=False,\n","    seed = 2019,\n","    roberta_model_name='roberta-base', # can also be exchnaged with roberta-large \n","    max_lr=1e-5,\n","    epochs=1,\n","    use_fp16=True,\n","    bs=32, \n","    max_seq_len=256, \n","    num_labels = 2,\n","    hidden_dropout_prob=.00,\n","    hidden_size=768, # 1024 for roberta-large\n","    start_tok = \"<s>\",\n","    end_tok = \"</s>\",\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.913197Z","start_time":"2019-09-02T13:42:47.475714Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:48.408927Z","iopub.status.busy":"2023-04-22T06:02:48.408440Z","iopub.status.idle":"2023-04-22T06:02:50.070471Z","shell.execute_reply":"2023-04-22T06:02:50.069630Z","shell.execute_reply.started":"2023-04-22T06:02:48.408878Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.917596Z","start_time":"2019-09-02T13:42:47.914436Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:50.073812Z","iopub.status.busy":"2023-04-22T06:02:50.073528Z","iopub.status.idle":"2023-04-22T06:02:50.079638Z","shell.execute_reply":"2023-04-22T06:02:50.076937Z","shell.execute_reply.started":"2023-04-22T06:02:50.073765Z"},"trusted":true},"outputs":[],"source":["if config.testing: df = df[:5000]\n","# print(df.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.934996Z","start_time":"2019-09-02T13:42:47.918828Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:50.082303Z","iopub.status.busy":"2023-04-22T06:02:50.081705Z","iopub.status.idle":"2023-04-22T06:02:50.103710Z","shell.execute_reply":"2023-04-22T06:02:50.102928Z","shell.execute_reply.started":"2023-04-22T06:02:50.081958Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.938328Z","start_time":"2019-09-02T13:42:47.936287Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:50.105651Z","iopub.status.busy":"2023-04-22T06:02:50.105200Z","iopub.status.idle":"2023-04-22T06:02:50.109662Z","shell.execute_reply":"2023-04-22T06:02:50.108703Z","shell.execute_reply.started":"2023-04-22T06:02:50.105466Z"},"trusted":true},"outputs":[],"source":["feat_cols = \"review\"\n","label_cols = \"sentiment\""]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:47.944376Z","start_time":"2019-09-02T13:42:47.940082Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:50.111802Z","iopub.status.busy":"2023-04-22T06:02:50.111305Z","iopub.status.idle":"2023-04-22T06:02:50.120968Z","shell.execute_reply":"2023-04-22T06:02:50.119833Z","shell.execute_reply.started":"2023-04-22T06:02:50.111588Z"},"trusted":true},"outputs":[],"source":["class FastAiRobertaTokenizer(BaseTokenizer):\n","    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n","    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): \n","        self._pretrained_tokenizer = tokenizer\n","        self.max_seq_len = max_seq_len \n","    def __call__(self, *args, **kwargs): \n","        return self \n","    def tokenizer(self, t:str) -> List[str]: \n","        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n","        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]"]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:48.296371Z","start_time":"2019-09-02T13:42:47.945766Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:50.122881Z","iopub.status.busy":"2023-04-22T06:02:50.122402Z","iopub.status.idle":"2023-04-22T06:02:52.595598Z","shell.execute_reply":"2023-04-22T06:02:52.594891Z","shell.execute_reply.started":"2023-04-22T06:02:50.122668Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 898823/898823 [00:00<00:00, 2059287.11B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 1303293.76B/s]\n"]}],"source":["# create fastai tokenizer for roberta\n","roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), \n","                             pre_rules=[], post_rules=[])"]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:48.407892Z","start_time":"2019-09-02T13:42:48.297631Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:52.597232Z","iopub.status.busy":"2023-04-22T06:02:52.596935Z","iopub.status.idle":"2023-04-22T06:02:52.770527Z","shell.execute_reply":"2023-04-22T06:02:52.769821Z","shell.execute_reply.started":"2023-04-22T06:02:52.597186Z"},"trusted":true},"outputs":[],"source":["# create fastai vocabulary for roberta\n","path = Path()\n","roberta_tok.save_vocabulary(path)\n","\n","with open('vocab.json', 'r') as f:\n","    roberta_vocab_dict = json.load(f)\n","    \n","fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:48.41299Z","start_time":"2019-09-02T13:42:48.409165Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:52.773598Z","iopub.status.busy":"2023-04-22T06:02:52.773046Z","iopub.status.idle":"2023-04-22T06:02:52.781153Z","shell.execute_reply":"2023-04-22T06:02:52.779974Z","shell.execute_reply.started":"2023-04-22T06:02:52.773536Z"},"trusted":true},"outputs":[],"source":["# Setting up pre-processors\n","class RobertaTokenizeProcessor(TokenizeProcessor):\n","    def __init__(self, tokenizer):\n","         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n","\n","class RobertaNumericalizeProcessor(NumericalizeProcessor):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, vocab=fastai_roberta_vocab, **kwargs)\n","\n","\n","def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n","    \"\"\"\n","    Constructing preprocessors for Roberta\n","    We remove sos and eos tokens since we add that ourselves in the tokenizer.\n","    We also use a custom vocabulary to match the numericalization with the original Roberta model.\n","    \"\"\"\n","    return [RobertaTokenizeProcessor(tokenizer=tokenizer), NumericalizeProcessor(vocab=vocab)]"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:48.421076Z","start_time":"2019-09-02T13:42:48.41423Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:52.782784Z","iopub.status.busy":"2023-04-22T06:02:52.782480Z","iopub.status.idle":"2023-04-22T06:02:52.793902Z","shell.execute_reply":"2023-04-22T06:02:52.792931Z","shell.execute_reply.started":"2023-04-22T06:02:52.782726Z"},"trusted":true},"outputs":[],"source":["# Creating a Roberta specific DataBunch class\n","class RobertaDataBunch(TextDataBunch):\n","    \"Create a `TextDataBunch` suitable for training Roberta\"\n","    @classmethod\n","    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,\n","               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, \n","               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:\n","        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n","        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n","        val_bs = ifnone(val_bs, bs)\n","        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n","        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)\n","        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n","        dataloaders = [train_dl]\n","        for ds in datasets[1:]:\n","            lengths = [len(t) for t in ds.x.items]\n","            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n","            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n","        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:48.428024Z","start_time":"2019-09-02T13:42:48.422267Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:52.796294Z","iopub.status.busy":"2023-04-22T06:02:52.795793Z","iopub.status.idle":"2023-04-22T06:02:52.805370Z","shell.execute_reply":"2023-04-22T06:02:52.804557Z","shell.execute_reply.started":"2023-04-22T06:02:52.796108Z"},"trusted":true},"outputs":[],"source":["class RobertaTextList(TextList):\n","    _bunch = RobertaDataBunch\n","    _label_cls = TextList"]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:42:51.659205Z","start_time":"2019-09-02T13:42:48.429219Z"},"execution":{"iopub.execute_input":"2023-04-22T06:02:52.807233Z","iopub.status.busy":"2023-04-22T06:02:52.806781Z","iopub.status.idle":"2023-04-22T06:04:07.214534Z","shell.execute_reply":"2023-04-22T06:04:07.213709Z","shell.execute_reply.started":"2023-04-22T06:02:52.807047Z"},"trusted":true},"outputs":[],"source":["# loading the tokenizer and vocab processors\n","processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)\n","\n","# creating our databunch \n","data = RobertaTextList.from_df(df, \".\", cols=feat_cols, processor=processor) \\\n","    .split_by_rand_pct(seed=config.seed) \\\n","    .label_from_df(cols=label_cols,label_cls=CategoryList) \\\n","    .databunch(bs=config.bs, pad_first=False, pad_idx=0)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-22T06:04:07.216458Z","iopub.status.busy":"2023-04-22T06:04:07.216169Z","iopub.status.idle":"2023-04-22T06:04:07.224489Z","shell.execute_reply":"2023-04-22T06:04:07.223753Z","shell.execute_reply.started":"2023-04-22T06:04:07.216411Z"},"trusted":true},"outputs":[],"source":["def get_preds_as_nparray(ds_type) -> np.ndarray:\n","    learn.model.roberta.eval()\n","    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()\n","    sampler = [i for i in data.dl(ds_type).sampler]\n","    reverse_sampler = np.argsort(sampler)\n","    ordered_preds = preds[reverse_sampler, :]\n","    pred_values = np.argmax(ordered_preds, axis=1)\n","    return ordered_preds, pred_values"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:49:09.101481Z","start_time":"2019-09-02T13:49:09.094984Z"},"execution":{"iopub.execute_input":"2023-04-22T06:04:07.226383Z","iopub.status.busy":"2023-04-22T06:04:07.225839Z","iopub.status.idle":"2023-04-22T06:04:07.236594Z","shell.execute_reply":"2023-04-22T06:04:07.235762Z","shell.execute_reply.started":"2023-04-22T06:04:07.226334Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from pytorch_transformers import RobertaModel\n","\n","# defining our model architecture \n","class CustomRobertaModel(nn.Module):\n","    def __init__(self,num_labels=2):\n","        super(CustomRobertaModel,self).__init__()\n","        self.num_labels = num_labels\n","        self.roberta = RobertaModel.from_pretrained(config.roberta_model_name)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, num_labels) # defining final output layer\n","        \n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n","        _ , pooled_output = self.roberta(input_ids, token_type_ids, attention_mask) # \n","        logits = self.classifier(pooled_output)        \n","        return logits"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T13:49:13.411872Z","start_time":"2019-09-02T13:49:09.914667Z"},"execution":{"iopub.execute_input":"2023-04-22T06:04:07.240002Z","iopub.status.busy":"2023-04-22T06:04:07.239698Z","iopub.status.idle":"2023-04-22T06:04:34.277125Z","shell.execute_reply":"2023-04-22T06:04:34.276350Z","shell.execute_reply.started":"2023-04-22T06:04:07.239942Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 481/481 [00:00<00:00, 186267.22B/s]\n","100%|██████████| 501200538/501200538 [00:17<00:00, 28788965.93B/s]\n"]}],"source":["roberta_model = CustomRobertaModel()\n","\n","\n","learn = Learner(data, roberta_model, metrics=[accuracy], loss_func=nn.CrossEntropyLoss())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T14:20:31.006732Z","start_time":"2019-09-02T14:14:45.072892Z"},"execution":{"iopub.execute_input":"2023-04-22T06:04:34.279207Z","iopub.status.busy":"2023-04-22T06:04:34.278712Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9423\n","\n","\n","Training with L2 regularization coefficient: 0.05\n"]},{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.120668</td>\n","      <td>0.160812</td>\n","      <td>0.946000</td>\n","      <td>14:33</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='17' class='' max='313', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      5.43% [17/313 00:04<01:17]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n","# learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)\n","\n","l2_reg_coeffs = [0.5, 0.1, 0.05, 0.01]\n","\n","for l2_reg_coeff in l2_reg_coeffs:\n","    print(f\"Training with L2 regularization coefficient: {l2_reg_coeff}\")\n","    optimizer = AdamW(learn.model.parameters(), lr=config.max_lr, weight_decay=l2_reg_coeff)\n","\n","    learn.model.roberta.train() # setting roberta to train as it is in eval mode by default\n","\n","    learn.fit_one_cycle(config.epochs, max_lr=slice(config.max_lr), wd=l2_reg_coeff)\n","    preds, pred_values = get_preds_as_nparray(DatasetType.Valid)\n","    print((pred_values == data.valid_ds.y.items).mean())\n","    print(\"\\n\")\n","# Modify optimizer to include weight decay for L2 regularization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T14:11:19.976614Z","start_time":"2019-09-02T14:11:19.970844Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T14:11:40.8352Z","start_time":"2019-09-02T14:11:20.102674Z"},"trusted":true},"outputs":[],"source":["preds, pred_values = get_preds_as_nparray(DatasetType.Valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2019-09-02T14:11:40.840225Z","start_time":"2019-09-02T14:11:40.837056Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# accuracy on valid\n","(pred_values == data.valid_ds.y.items).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}
